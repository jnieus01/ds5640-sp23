---
title: "HW 03"
author: "Jordan Nieusma"
date: "2023-02-14"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Assignment tasks: 
[X] Use the prostate cancer data.

```{r libraries}
library('splines')        ## for 'bs'
library('dplyr')          ## for 'select', 'filter', and others
library('magrittr')       ## for '%<>%' operator
library('glmnet')         ## for 'glmnet' 
```
```{r}
# load prostate data
prostate <- 
  read.table(url(
    'https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data'))

## split prostate into testing and training subsets
prostate_train <- prostate %>%
  filter(train == TRUE) %>% 
  select(-train)

prostate_test <- prostate %>%
  filter(train == FALSE) %>% 
  select(-train)

x_train <- prostate_train %>%
  select(-lcavol)

x_test  <- prostate_test %>%
  select(-lcavol)

y_train <- prostate_train %>%
  select(lcavol)

y_test <- prostate_test %>%
  select(lcavol)

```



[X] Use the cor function to reproduce the correlations listed in HTF Table 3.1, page 50.

```{r corr-table}
prostate_corr <- prostate %>%
  select(lcavol, lweight, age, lbph, svi, lcp, gleason)
x <- prostate_corr %>% select(-lcavol)
y <- prostate_corr %>% select(-gleason)

corr_matrix = cor(x, y)

corr_matrix[upper.tri(corr_matrix)] <-  NA 
corr_matrix
```

[X] Treat lcavol as the outcome, and use all other variables in the data set as predictors.
[X] With the training subset of the prostate data, train a least-squares regression model with all predictors using the lm function.

```{r predict-lcavol}
## split data into train/test
prostate_train <- prostate %>%
  filter(train == TRUE) %>% 
  select(-train)

prostate_test <- prostate %>%
  filter(train == FALSE) %>% 
  select(-train)

# remove lcavol from x
x_train <- prostate_train %>%
  select(-lcavol)

x_test  <- prostate_test %>%
  select(-lcavol)

y_train <- prostate_train$lcavol

y_test <- prostate_test$lcavol

```
```{r}
# fit linear model
lcavol_fit <- lm(y_train ~ x_train$lweight + x_train$age + x_train$lbph + x_train$svi + x_train$lcp + x_train$gleason + x_train$pgg45 + x_train$lpsa)
lcavol_fit
```


[] Use the testing subset to compute the test error (average squared-error loss) using the fitted least-squares regression model.
```{r}
## test_error 
L2_loss <- function(y, yhat)
  (y-yhat)^2

## functions to compute testing/training error with lm
error <- function(dat, fit, loss=L2_loss) {
  y_hat <- predict.lm(fit, newdata=dat)
  mean(loss(dat$lcavol, y_test))
}

test_error <- error(prostate_test, lcavol_fit)
test_error
```

[] Train a ridge regression model using the glmnet function, and tune the value of lambda (i.e., use guess and check to find the value of lambda that approximately minimizes the test error).

```{r}
# TODO 
```


[] Create a figure that shows the training and test error associated with ridge regression as a function of lambda
[] Create a path diagram of the ridge regression analysis, similar to HTF Figure 3.8

```{r}
# TODO
```

